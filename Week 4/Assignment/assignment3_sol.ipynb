{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aabbIB92YA8"
      },
      "source": [
        "# Question 1 : Classification using Naive Bayes\n",
        "\n",
        "Can glucose and blood pressure data classify whether a patient has diabetes or not ? If yes, which classification algorithm should you use ?\n",
        "\n",
        "The dataset **diabetes_classification.csv** has 3 columns and 995 entries with the above data.\n",
        "\n",
        "\n",
        "1. Load the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Ytm1udmGNwSl"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>glucose</th>\n",
              "      <th>bloodpressure</th>\n",
              "      <th>diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40</td>\n",
              "      <td>85</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40</td>\n",
              "      <td>92</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>45</td>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>40</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   glucose  bloodpressure  diabetes\n",
              "0       40             85         0\n",
              "1       40             92         0\n",
              "2       45             63         1\n",
              "3       45             80         0\n",
              "4       40             73         1"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "data=pd.read_csv(\"diabetes.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRcqHcd_5XUt"
      },
      "source": [
        "2. The dataset has two feature columns and one target column. Plot a bar graph or histogram showing the distribution of values in the feature columns (count of each value)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "VdiNiiJdNy-K"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data[\"diabetes\"].hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa-7s9hL5tii"
      },
      "source": [
        " The feature column **glucose** has a somewhat Gaussian distribution of data. So we will try out Gaussian Naive Bayes classification for the data using Scikit-Learn.\n",
        "\n",
        "3. Split the dataset.\n",
        "4. Fit a Gaussian NB model on the data. Make predictions and find the accuracy score.\n",
        "\n",
        "Optional :\n",
        "5. Compare the model with other classification algorithms like Logistic Regression, KNN, decision tree etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "_qc64PVrN1-y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9116465863453815\n"
          ]
        }
      ],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "train,test=train_test_split(data,test_size=0.25)\n",
        "X_test = test.iloc[:,:-1].values\n",
        "Y_test = test.iloc[:,-1].values\n",
        "\n",
        "def calculate_prior(data, Y):\n",
        "    classes = sorted(list(data[Y].unique()))\n",
        "    prior = []\n",
        "    for i in classes:\n",
        "        prior.append(len(data[data[Y]==i])/len(data))\n",
        "    return prior\n",
        "\n",
        "def calculate_likelihood_categorical(data, feat_name, feat_val, Y, label):\n",
        "    feat = list(data.columns)\n",
        "    data = data[data[Y]==label]\n",
        "    p_x_given_y = len(data[data[feat_name]==feat_val]) / len(data)\n",
        "    return p_x_given_y\n",
        "\n",
        "def naive_bayes_categorical(data, X, Y):\n",
        "    features = list(data.columns)[:-1]\n",
        "\n",
        "    prior = calculate_prior(data, Y)\n",
        "\n",
        "    Y_pred = []\n",
        "\n",
        "    for x in X:\n",
        "\n",
        "        labels = sorted(list(data[Y].unique()))\n",
        "        likelihood = [1]*len(labels)\n",
        "        for j in range(len(labels)):\n",
        "            for i in range(len(features)):\n",
        "                likelihood[j] *= calculate_likelihood_categorical(data, features[i], x[i], Y, labels[j])\n",
        "\n",
        "        post_prob = [1]*len(labels)\n",
        "        for j in range(len(labels)):\n",
        "            post_prob[j] = likelihood[j] * prior[j]\n",
        "\n",
        "        Y_pred.append(np.argmax(post_prob))\n",
        "\n",
        "    return np.array(Y_pred) \n",
        "\n",
        "Y_pred = naive_bayes_categorical(train, X=X_test, Y=\"diabetes\")\n",
        "\n",
        "from sklearn.metrics import accuracy_score   \n",
        "score = accuracy_score(Y_test, Y_pred)  \n",
        "print(score)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSniomr219vK"
      },
      "source": [
        "# Question 2 : Regression using SVM and Tree Algorithms\n",
        "\n",
        "In this question, we will be using the **insurance.csv** file which contain information on insurance charges based on the following informations: age,sex,bmi,region,number of children and whether the person is a smoker or not. You need to predict the charges based on the information given.\n",
        "\n",
        "### 1. Load the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "TIzySehxN3nw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1338 entries, 0 to 1337\n",
            "Data columns (total 7 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       1338 non-null   int64  \n",
            " 1   sex       1338 non-null   object \n",
            " 2   bmi       1338 non-null   float64\n",
            " 3   children  1338 non-null   int64  \n",
            " 4   smoker    1338 non-null   object \n",
            " 5   region    1338 non-null   object \n",
            " 6   charges   1338 non-null   float64\n",
            "dtypes: float64(2), int64(2), object(3)\n",
            "memory usage: 73.3+ KB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "data=pd.read_csv(\"insurance.csv\")\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3kLtntR2_wm"
      },
      "source": [
        "### 2. Separate the numerical and categorical columns.\n",
        "### 3. Label Encode the categorical columns.\n",
        "### 4. Scale the numerical columns. (Scale the charges separately so that you can calculate errors afterwards.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "B5BlzbzGN4vq"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>charges</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.021739</td>\n",
              "      <td>0.321227</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.251611</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.479150</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.009636</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.217391</td>\n",
              "      <td>0.458434</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.053115</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.326087</td>\n",
              "      <td>0.181464</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333010</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.304348</td>\n",
              "      <td>0.347592</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043816</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>0.695652</td>\n",
              "      <td>0.403820</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.151299</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.429379</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017305</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.562012</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008108</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>0.065217</td>\n",
              "      <td>0.264730</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.014144</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>0.934783</td>\n",
              "      <td>0.352704</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.447249</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           age       bmi  children   charges  sex  smoker  region\n",
              "0     0.021739  0.321227       0.0  0.251611    0       1       3\n",
              "1     0.000000  0.479150       0.2  0.009636    1       0       2\n",
              "2     0.217391  0.458434       0.6  0.053115    1       0       2\n",
              "3     0.326087  0.181464       0.0  0.333010    1       0       1\n",
              "4     0.304348  0.347592       0.0  0.043816    1       0       1\n",
              "...        ...       ...       ...       ...  ...     ...     ...\n",
              "1333  0.695652  0.403820       0.6  0.151299    1       0       1\n",
              "1334  0.000000  0.429379       0.0  0.017305    0       0       0\n",
              "1335  0.000000  0.562012       0.0  0.008108    0       0       2\n",
              "1336  0.065217  0.264730       0.0  0.014144    0       0       3\n",
              "1337  0.934783  0.352704       0.0  0.447249    0       1       1\n",
              "\n",
              "[1338 rows x 7 columns]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "numeric_data = data.select_dtypes(include=[np.number])\n",
        "categorical_data = data.select_dtypes(exclude=[np.number])\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "categorical_data['sex']= le.fit_transform(categorical_data['sex'])\n",
        "categorical_data['smoker']= le.fit_transform(categorical_data['smoker'])\n",
        "categorical_data['region']= le.fit_transform(categorical_data['region'])\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "numeric_data[[\"age\",\"bmi\",\"children\"]]=scaler.fit_transform(numeric_data[[\"age\",\"bmi\",\"children\"]])\n",
        "numeric_data[[\"charges\"]]=scaler.fit_transform(numeric_data[[\"charges\"]])\n",
        "data=pd.concat([numeric_data,categorical_data],axis=1)\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAr0_8zS3d4M"
      },
      "source": [
        "### 5. Split the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "q0puLu0rN6Gi"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.02173913, 0.37826204, 0.        , 0.51374972, 0.        ,\n",
              "        1.        ],\n",
              "       [0.5       , 0.15657789, 0.2       , 0.08221424, 1.        ,\n",
              "        0.        ],\n",
              "       [0.17391304, 0.36373419, 0.2       , 0.03624172, 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.04347826, 0.22760291, 0.        , 0.39911218, 0.        ,\n",
              "        1.        ],\n",
              "       [0.        , 0.48210923, 0.        , 0.16537909, 0.        ,\n",
              "        0.        ],\n",
              "       [0.97826087, 0.56201238, 0.        , 0.20377317, 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x=data.iloc[:,:-1].values\n",
        "y=data.iloc[:,-1].values\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25)\n",
        "x_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JKtZ3nN3gmZ"
      },
      "source": [
        "### 6. Support Vector Regressor\n",
        "\n",
        "Here , you will use the SVR model from sklearn.svm and fit it on the training data. Then predict on the test data and calaculate MAE, MSE. But...\n",
        "\n",
        "The SVR class contains many hyperparameters, example : kernel can have the following values : linear, rbf, poly, sigmoid.\n",
        "\n",
        "Use **RandomizedSearchCV** from sklearn.model_selection , create a dictionary with keys 'kernel' and 'gamma' . As values of the keys, create a list of some possible values. Run a 3-fold cross validation test (cv=3) and find the best parameters. Then initiate the SVR model with those parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "TTXaAbc7N7oS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best parameters: {'kernel': 'linear', 'gamma': 'scale'}\n",
            "MAE: 0.9694826552324816\n",
            "MSE: 1.2970145696720816\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "svr=SVR()\n",
        "hyperparam={'kernel':['linear','rbf','poly','sigmoid'],'gamma':['scale','auto']}\n",
        "rnd_search = RandomizedSearchCV(svr, hyperparam, n_iter =4, cv=3)\n",
        "rnd_search.fit(x_train,y_train)\n",
        "param=rnd_search.best_params_\n",
        "svr=SVR(kernel=param['kernel'],gamma=param['gamma'])\n",
        "svr.fit(x_train,y_train)\n",
        "y_pred = svr.predict(x_test)\n",
        "mae_svr = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"best parameters:\", param)\n",
        "print(\"MAE:\", mae_svr)\n",
        "print(\"MSE:\", mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGt147zA5E6f"
      },
      "source": [
        "### 7. AdaBoost Regressor\n",
        "\n",
        "We would do similar for AdaBoostRegressor from sklearn.ensemble . Here, the hyperparameters are n_estimators and loss.\n",
        "\n",
        "Instead of RandomizedSearchCV, let's try GridSearchCV . Find the best parameters and then find errors on test data using the model with best parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "u5c-EFdtN9Wt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best parameters: {'loss': 'linear', 'n_estimators': 139}\n",
            "MAE: 0.9765669490166234\n",
            "MSE: 1.2297287517418352\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "abr=AdaBoostRegressor()\n",
        "hyperparam={'n_estimators':list(range(50,200)),'loss':['linear', 'square', 'exponential']}\n",
        "grid_search = GridSearchCV(abr, hyperparam, cv=3)\n",
        "grid_search.fit(x_train,y_train)\n",
        "param=grid_search.best_params_\n",
        "abr=AdaBoostRegressor(n_estimators=param['n_estimators'],loss=param['loss'])\n",
        "abr.fit(x_train,y_train)\n",
        "y_pred = abr.predict(x_test)\n",
        "mae_abr = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"best parameters:\", param)\n",
        "print(\"MAE:\", mae_abr)\n",
        "print(\"MSE:\", mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW11faHs5nH_"
      },
      "source": [
        "8. Now carry the same procedure for Random Forest Regressor and for Gradient Boosting Regression.\n",
        "9. Finally, use <a href=\"https://xgboost.readthedocs.io/en/stable/get_started.html\"> XGBoost Regressor </a> and compare all the models. Comment which model had the least error (MAE and MSE).\n",
        "You will be required to run  <code> !pip install xgboost </code> to import xgboost models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "bg_amvWHOAJG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomForestRegressor :\n",
            "best parameters: {'n_estimators': 190}\n",
            "MAE: 0.9340141398271797\n",
            "MSE: 1.2489297556538637\n",
            "GradientBoostingRegressor :\n",
            "best parameters: {'n_estimators': 57}\n",
            "MAE: 0.9368279075272302\n",
            "MSE: 1.1955377820991888\n",
            "xgboost :\n",
            "best parameters: {'gamma': 2, 'max_depth': 4}\n",
            "MAE: 0.9264377008623151\n",
            "MSE: 1.1974514361360167\n",
            "minimum MAE =  0.9264377008623151\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import xgboost\n",
        "\n",
        "rfr = RandomForestRegressor()\n",
        "hyperparam={'n_estimators':list(range(50,200))}\n",
        "grid_search = GridSearchCV(rfr, hyperparam, cv = 3)\n",
        "grid_search.fit(x_train, y_train)\n",
        "param=grid_search.best_params_\n",
        "rfr= RandomForestRegressor(n_estimators=param['n_estimators'])\n",
        "rfr.fit(x_train,y_train)\n",
        "y_pred = rfr.predict(x_test)\n",
        "mae_rfr = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"RandomForestRegressor :\")\n",
        "print(\"best parameters:\", param)\n",
        "print(\"MAE:\", mae_rfr)\n",
        "print(\"MSE:\", mse)\n",
        "\n",
        "gbr = GradientBoostingRegressor()\n",
        "hyperparam={'n_estimators':list(range(50,200))}\n",
        "grid_search = GridSearchCV(gbr, hyperparam, cv = 3)\n",
        "grid_search.fit(x_train, y_train)\n",
        "param=grid_search.best_params_\n",
        "gbr= GradientBoostingRegressor(n_estimators=param['n_estimators'])\n",
        "gbr.fit(x_train,y_train)\n",
        "y_pred = gbr.predict(x_test)\n",
        "mae_gbr = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"GradientBoostingRegressor :\")\n",
        "print(\"best parameters:\", param)\n",
        "print(\"MAE:\", mae_gbr)\n",
        "print(\"MSE:\", mse)\n",
        "\n",
        "xgb=xgboost.XGBRegressor()\n",
        "hyperparam={'gamma':list(range(0,10)),'max_depth':list(range(1,10))}\n",
        "grid_search = GridSearchCV(xgb, hyperparam, cv = 10)\n",
        "grid_search.fit(x_train, y_train)\n",
        "param=grid_search.best_params_\n",
        "xgb= xgboost.XGBRegressor(gamma=param['gamma'],max_depth=param['max_depth'])\n",
        "xgb.fit(x_train,y_train)\n",
        "y_pred = xgb.predict(x_test)\n",
        "mae_xgb = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"xgboost :\")\n",
        "print(\"best parameters:\", param)\n",
        "print(\"MAE:\", mae_xgb)\n",
        "print(\"MSE:\", mse)\n",
        "\n",
        "print(\"minimum MAE = \",min(mae_abr,mae_gbr,mae_rfr,mae_svr,mae_xgb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMMzdz1e3YMp"
      },
      "source": [
        "# Question 3 : Classification using SVM and Tree Algorithms\n",
        "\n",
        "In this question, we will be using the **bookmyshow_ads.csv** file which contain information on whether an url is spam or not based on 32 features. You need to classify the url as spam or not spam based on the information given.\n",
        "\n",
        "### 1. Load the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "HZTHOA-KOLTw"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>having_IPhaving_IP_Address</th>\n",
              "      <th>URLURL_Length</th>\n",
              "      <th>Shortining_Service</th>\n",
              "      <th>having_At_Symbol</th>\n",
              "      <th>double_slash_redirecting</th>\n",
              "      <th>Prefix_Suffix</th>\n",
              "      <th>having_Sub_Domain</th>\n",
              "      <th>SSLfinal_State</th>\n",
              "      <th>Domain_registeration_length</th>\n",
              "      <th>...</th>\n",
              "      <th>popUpWidnow</th>\n",
              "      <th>Iframe</th>\n",
              "      <th>age_of_domain</th>\n",
              "      <th>DNSRecord</th>\n",
              "      <th>web_traffic</th>\n",
              "      <th>Page_Rank</th>\n",
              "      <th>Google_Index</th>\n",
              "      <th>Links_pointing_to_page</th>\n",
              "      <th>Statistical_report</th>\n",
              "      <th>Result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  index  having_IPhaving_IP_Address  URLURL_Length  Shortining_Service   \n",
              "0     1                           0              1                   1  \\\n",
              "1     2                           1              1                   1   \n",
              "2     3                           1             -1                   1   \n",
              "3     4                           1             -1                   1   \n",
              "4     5                           1             -1                   0   \n",
              "\n",
              "   having_At_Symbol  double_slash_redirecting  Prefix_Suffix   \n",
              "0                 1                         0              0  \\\n",
              "1                 1                         1              0   \n",
              "2                 1                         1              0   \n",
              "3                 1                         1              0   \n",
              "4                 1                         1              0   \n",
              "\n",
              "   having_Sub_Domain  SSLfinal_State  Domain_registeration_length  ...   \n",
              "0                  0               0                            0  ...  \\\n",
              "1                 -1               1                            0  ...   \n",
              "2                  0               0                            0  ...   \n",
              "3                  0               0                            1  ...   \n",
              "4                  1               1                            0  ...   \n",
              "\n",
              "   popUpWidnow  Iframe  age_of_domain  DNSRecord  web_traffic  Page_Rank   \n",
              "0            1       1              0          0            0          0  \\\n",
              "1            1       1              0          0           -1          0   \n",
              "2            1       1              1          0            1          0   \n",
              "3            1       1              0          0            1          0   \n",
              "4            0       1              0          0           -1          0   \n",
              "\n",
              "   Google_Index  Links_pointing_to_page  Statistical_report  Result  \n",
              "0             1                       1                   0       0  \n",
              "1             1                       1                   1       0  \n",
              "2             1                      -1                   0       0  \n",
              "3             1                       0                   1       0  \n",
              "4             1                       1                   1       1  \n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "data=pd.read_csv(\"bookmyshow_ads.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcqJmRVyLHFU"
      },
      "source": [
        "### 2. Split the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "7b7dtEdwOMnQ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0,  0,  1, ...,  1,  1,  1],\n",
              "       [ 1,  0,  0, ...,  1, -1,  1],\n",
              "       [ 1,  0,  1, ...,  1, -1,  0],\n",
              "       ...,\n",
              "       [ 1,  0,  1, ...,  1, -1,  1],\n",
              "       [ 0,  0,  0, ...,  1,  0,  0],\n",
              "       [ 1,  0,  1, ...,  1, -1,  1]])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics  \n",
        "from sklearn.metrics import accuracy_score  \n",
        "x=data.iloc[:,1:-1].values\n",
        "y=data.iloc[:,-1].values\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25)\n",
        "\n",
        "x_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKX0BSiILMPe"
      },
      "source": [
        "### 3. Model Comparison\n",
        "\n",
        "Similar to the previous question, use the following classifier models from sklearn and compare them:\n",
        "1. Decision Tree\n",
        "2. Random Forest\n",
        "3. Adaboost\n",
        "4. Gradient Boost\n",
        "5. XGBoost\n",
        "\n",
        "For each model, you may also try to find the best hyperparameters using GridSearch Cross Validation or RandomizedSearch Cross Validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "YaTC1pJFOPNF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Desicion tree accuracy =  0.9290882778581766\n",
            "Random Forest accuracy =  0.9710564399421129\n",
            "Adaboost accuracy =  0.9316208393632417\n",
            "Gradient boost accuracy =  0.9486251808972503\n",
            "XGBoost =  0.965629522431259\n"
          ]
        }
      ],
      "source": [
        "# Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf1 = DecisionTreeClassifier(criterion='entropy',max_depth=5)\n",
        "clf1.fit(x_train,y_train)\n",
        "y_pred1= clf1.predict(x_test)\n",
        "print(\"Desicion tree accuracy = \",accuracy_score(y_test, y_pred1))\n",
        "\n",
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf2 = RandomForestClassifier(n_estimators = 100)  \n",
        "clf2.fit(x_train, y_train)\n",
        "y_pred2 = clf2.predict(x_test)\n",
        "print(\"Random Forest accuracy = \",accuracy_score(y_test, y_pred2))\n",
        "\n",
        "#Adaboost\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "clf3 = AdaBoostClassifier()\n",
        "clf3.fit(x_train,y_train)\n",
        "y_pred3 = clf3.predict(x_test)\n",
        "print(\"Adaboost accuracy = \",accuracy_score(y_test, y_pred3))\n",
        "\n",
        "#Gradient Boost\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "clf4 = GradientBoostingClassifier(n_estimators=300,learning_rate=0.05,max_features=10)\n",
        "clf4.fit(x_train,y_train)\n",
        "y_pred4 = clf4.predict(x_test)\n",
        "print(\"Gradient boost accuracy = \",accuracy_score(y_test, y_pred4))\n",
        "\n",
        "#XGBoost\n",
        "import xgboost as xgb \n",
        "clf5 = xgb.XGBClassifier() \n",
        "clf5.fit(x_train,y_train) \n",
        "y_pred5 = clf5.predict(x_test)\n",
        "print(\"XGBoost = \",accuracy_score(y_test, y_pred5))                                \n",
        "                                \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbMIyf8ouk1u"
      },
      "source": [
        "# Question 4 : Clustering\n",
        "\n",
        "Customer Segmentation is the subdivision of a market into discrete customer groups that share similar characteristics. Customer Segmentation can be a powerful means to identify unsatisfied customer needs.\n",
        "\n",
        "The csv file **segmentation data.csv** contains basic data about some customers like Customer ID, age, gender, annual income and spending score. You want to classify the customers into different groups so that marketing strategy could be planned in the future accordingly. How many different groups should be made ? What should be the approach ?\n",
        "\n",
        "This is an Unsupervised Learning question since it doesn't provide you with labels - the groups. \n",
        "\n",
        "### 1. Import the necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UKGseStOQgk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXs9rQC0u3_S"
      },
      "source": [
        "### 2. Read the csv file \"segmentation data.csv\" present in the Github repository as a Pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfiso96cORzB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkoXSkGvvEfQ"
      },
      "source": [
        "### 3. Do the necessary preprocessing of the data.\n",
        "\n",
        "> Drop unwanted columns.\n",
        "\n",
        "> Check for null values.\n",
        "\n",
        "> Scale the numerical columns.\n",
        "\n",
        "> Additionally, you may also make the Age column have categorical values. How ? Apply some function that makes age groups turns all ages in some group to a particular number !\n",
        "\n",
        "Note : Don't do everything in a single code block ! Do it step-by-step and show output for each step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8T3S0J0OUS_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI5spEOLB2Sw"
      },
      "source": [
        "### 4. KMeans Model Training - Scikit-Learn\n",
        "\n",
        "At first, let's try to implement KMeans Clustering using sklearn.clusters.KMeans .\n",
        "\n",
        "How to decide for the value 'K' ?\n",
        "\n",
        "Read the following blog. It provides different ways of evaluating clustering algorithms.\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2021/05/k-mean-getting-the-optimal-number-of-clusters\n",
        "\n",
        "We will be looking on two methods : Elbow Method, Silhouette Analysis.\n",
        "\n",
        "**Make a list of values for K , ranging from 2 to 10. For each K, fit a model, calculate the inertia and silhouette scores. Plot them. Decide which value of K is optimal !**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onhGIzLqOX8p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jajN40GH0EP"
      },
      "source": [
        "### 5. KMeans Model Prediction\n",
        "\n",
        "Once you decided the optimal K, once again fit a model with that K value and store the silhouette score and the labels for the entire data.\n",
        "\n",
        "It is observed that the optimal value of k is 4. So, let's store the values of inertia and labels for k=4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qydGd1rYOZqx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fjt3IhXzYgz"
      },
      "source": [
        "### 6. KMeans Model Training - Scratch\n",
        "\n",
        "Now, code the KMeans Model from scratch. Train it on the data, and try to find out when you have the labels with maximum accuracy when compared to the labels of the SkLearn model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PT3TD5uqOber"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTWu6y8S0Usv"
      },
      "source": [
        "### 7. DBSCAN model training - Scikit-Learn\n",
        "\n",
        "Using sklear.clusters.DBSCAN, you have to fit a model on the data.\n",
        "\n",
        "But, here we would like to deal with two hyperparameters : epsilon and minimum number of samples.\n",
        "\n",
        "Make two lists. One with some probable values for epsilon, other with probable values for min_samples.\n",
        "\n",
        "Example : eps= [0.1,0.2,0.5,1,2] , min_samples=[3,4,5,6]\n",
        "\n",
        "Run a nested loop. for each value of eps and min_samples, fit a dbscan model on the data and calculate the silhouette score. Find the parameters for which the silhouette score is maximum."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NM5XJSZYOdmB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T77d9N4w1hRI"
      },
      "source": [
        "### 8. DBSCAN model training - Scratch\n",
        "\n",
        "Code the DBScan model. For the same epsilon and min_samples values, fit the model on the data. You should receive the same silhouette score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ULTd8n1Oc17"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
